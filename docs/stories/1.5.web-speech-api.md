# 1.5 Web Speech API Integration

## –°—Ç–∞—Ç—É—Å: üöß –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

## –û–ø–∏—Å–∞–Ω–∏–µ

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Web Speech API –≤ Electron overlay –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–≤—É—Ö —Ä–µ–∂–∏–º–æ–≤ –æ—Ç–ø—Ä–∞–≤–∫–∏ (auto-send –∏ trigger word), –º–µ—Ö–∞–Ω–∏–∑–º–∞ auto-restart –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –±—Ä–∞—É–∑–µ—Ä–∞.

## –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

- **Send modes (auto-send / trigger word)** (‚≠ê‚≠ê‚≠ê) - –î–≤–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã —Å utterances
- **Auto-restart –º–µ—Ö–∞–Ω–∏–∑–º** (‚≠ê‚≠ê‚≠ê) - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫ –∏ timeout
- **Permission handling** (‚≠ê‚≠ê) - –ó–∞–ø—Ä–æ—Å –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MCP server** (‚≠ê‚≠ê‚≠ê) - –û—Ç–ø—Ä–∞–≤–∫–∞ utterances –≤ MCP server

## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

- ‚úÖ Story 1.4 - Overlay UI & Animations (–∑–∞–≤–µ—Ä—à–µ–Ω–æ)

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### 1. Web Speech API Setup

#### 1.1 SpeechRecognition Interface

```typescript
// electron/renderer/speech/speech-recognition.ts
interface SpeechRecognitionConfig {
  lang: string;           // 'ru-RU', 'en-US'
  continuous: boolean;    // –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
  interimResults: boolean; // –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
  maxAlternatives: number; // –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
}

class SpeechRecognitionManager {
  private recognition: SpeechRecognition | null = null;
  private isListening = false;
  private restartAttempts = 0;
  private maxRestartAttempts = 5;

  constructor(private config: SpeechRecognitionConfig) {}

  async start(): Promise<void> {
    if (!this.isSupported()) {
      throw new Error('Web Speech API not supported');
    }

    if (this.isListening) {
      console.warn('Already listening');
      return;
    }

    await this.requestMicrophonePermission();
    this.initializeRecognition();
    this.recognition!.start();
    this.isListening = true;
  }

  stop(): void {
    if (!this.isListening) return;

    this.recognition?.stop();
    this.isListening = false;
    this.restartAttempts = 0;
  }

  isSupported(): boolean {
    return 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
  }

  private initializeRecognition(): void {
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;

    this.recognition = new SpeechRecognition();
    this.recognition.lang = this.config.lang;
    this.recognition.continuous = this.config.continuous;
    this.recognition.interimResults = this.config.interimResults;
    this.recognition.maxAlternatives = this.config.maxAlternatives;

    this.setupEventHandlers();
  }

  private setupEventHandlers(): void {
    if (!this.recognition) return;

    this.recognition.onstart = () => {
      console.log('Speech recognition started');
      this.onStart?.();
    };

    this.recognition.onresult = (event) => {
      this.handleResult(event);
    };

    this.recognition.onerror = (event) => {
      this.handleError(event);
    };

    this.recognition.onend = () => {
      console.log('Speech recognition ended');
      this.handleEnd();
    };
  }

  private handleResult(event: SpeechRecognitionEvent): void {
    const results = event.results;
    const lastResult = results[results.length - 1];

    if (lastResult.isFinal) {
      const transcript = lastResult[0].transcript;
      const confidence = lastResult[0].confidence;

      this.onFinalResult?.({ transcript, confidence });
    } else {
      const transcript = lastResult[0].transcript;
      this.onInterimResult?.({ transcript });
    }
  }

  private handleError(event: SpeechRecognitionErrorEvent): void {
    console.error('Speech recognition error:', event.error);

    this.onError?.({
      error: event.error,
      message: this.getErrorMessage(event.error)
    });

    // –ü–æ–ø—ã—Ç–∫–∞ auto-restart –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö –æ—à–∏–±–∫–∞—Ö
    if (this.shouldAutoRestart(event.error)) {
      this.attemptRestart();
    } else {
      this.isListening = false;
    }
  }

  private handleEnd(): void {
    this.isListening = false;

    // Auto-restart –µ—Å–ª–∏ listening –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω
    if (this.restartAttempts < this.maxRestartAttempts) {
      this.attemptRestart();
    } else {
      this.onEnd?.();
    }
  }

  private shouldAutoRestart(error: SpeechRecognitionErrorCode): boolean {
    // –°–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å
    const restartableErrors: SpeechRecognitionErrorCode[] = [
      'network',
      'no-speech',
      'aborted'
    ];

    return restartableErrors.includes(error);
  }

  private async attemptRestart(): Promise<void> {
    this.restartAttempts++;

    const delay = Math.min(1000 * this.restartAttempts, 5000); // Max 5 —Å–µ–∫—É–Ω–¥
    console.log(`Attempting restart (${this.restartAttempts}/${this.maxRestartAttempts}) in ${delay}ms`);

    await new Promise(resolve => setTimeout(resolve, delay));

    if (this.restartAttempts < this.maxRestartAttempts) {
      try {
        this.start();
      } catch (error) {
        console.error('Restart failed:', error);
        this.onEnd?.();
      }
    } else {
      console.error('Max restart attempts reached');
      this.onEnd?.();
    }
  }

  private getErrorMessage(error: SpeechRecognitionErrorCode): string {
    const messages: Record<SpeechRecognitionErrorCode, string> = {
      'no-speech': 'No speech detected. Please speak into the microphone.',
      'aborted': 'Speech recognition aborted.',
      'audio-capture': 'Microphone not available or blocked.',
      'network': 'Network error occurred.',
      'not-allowed': 'Microphone permission denied.',
      'service-not-allowed': 'Speech service not allowed.',
      'bad-grammar': 'Grammar error.',
      'language-not-supported': 'Language not supported.'
    };

    return messages[error] || `Unknown error: ${error}`;
  }

  private async requestMicrophonePermission(): Promise<void> {
    try {
      await navigator.mediaDevices.getUserMedia({ audio: true });
    } catch (error) {
      throw new Error('Microphone permission denied');
    }
  }

  // Event callbacks
  onStart?: () => void;
  onFinalResult?: (result: { transcript: string; confidence: number }) => void;
  onInterimResult?: (result: { transcript: string }) => void;
  onError?: (error: { error: SpeechRecognitionErrorCode; message: string }) => void;
  onEnd?: () => void;
}
```

### 2. Send Modes Implementation

#### 2.1 Auto-Send Mode (–ø–æ –ø–∞—É–∑–µ)

```typescript
// electron/renderer/speech/modes/auto-send.ts
export class AutoSendMode {
  private pendingTranscript = '';
  private silenceTimeout: number | null = null;
  private readonly silenceDelay = 1500; // 1.5 —Å–µ–∫—É–Ω–¥—ã –ø–∞—É–∑—ã

  constructor(
    private onSend: (text: string) => void,
    private onInterimUpdate: (text: string) => void
  ) {}

  handleInterimResult(transcript: string): void {
    this.pendingTranscript = transcript;
    this.onInterimUpdate(transcript);
    this.resetSilenceTimer();
  }

  handleFinalResult(transcript: string, confidence: number): void {
    this.pendingTranscript = transcript;
    this.onInterimUpdate(transcript);

    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π
    this.resetSilenceTimer();
  }

  private resetSilenceTimer(): void {
    if (this.silenceTimeout !== null) {
      clearTimeout(this.silenceTimeout);
    }

    this.silenceTimeout = window.setTimeout(() => {
      if (this.pendingTranscript.trim()) {
        this.send();
      }
    }, this.silenceDelay);
  }

  private send(): void {
    const text = this.pendingTranscript.trim();
    if (text) {
      this.onSend(text);
      this.pendingTranscript = '';
      this.onInterimUpdate('');
    }

    if (this.silenceTimeout !== null) {
      clearTimeout(this.silenceTimeout);
      this.silenceTimeout = null;
    }
  }

  clear(): void {
    this.pendingTranscript = '';
    this.onInterimUpdate('');

    if (this.silenceTimeout !== null) {
      clearTimeout(this.silenceTimeout);
      this.silenceTimeout = null;
    }
  }

  getPendingText(): string {
    return this.pendingTranscript;
  }
}
```

#### 2.2 Trigger Word Mode

```typescript
// electron/renderer/speech/modes/trigger-word.ts
export class TriggerWordMode {
  private pendingTranscripts: string[] = [];
  private triggerWord: string = 'send';

  constructor(
    private onSend: (text: string) => void,
    private onQueueUpdate: (queue: string[]) => void
  ) {}

  setTriggerWord(word: string): void {
    this.triggerWord = word.toLowerCase();
  }

  handleInterimResult(transcript: string): void {
    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ UI
    this.onQueueUpdate([...this.pendingTranscripts, transcript]);
  }

  handleFinalResult(transcript: string, confidence: number): void {
    const text = transcript.trim();
    if (!text) return;

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ trigger word
    const lowerText = text.toLowerCase();
    const hasTriggerWord = lowerText.includes(this.triggerWord);

    if (hasTriggerWord) {
      // –£–¥–∞–ª—è–µ–º trigger word –∏–∑ —Ç–µ–∫—Å—Ç–∞
      const cleanedText = this.removeTriggerWord(text);

      if (cleanedText) {
        this.pendingTranscripts.push(cleanedText);
      }

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å—ë –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ
      this.sendAll();
    } else {
      // –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
      this.pendingTranscripts.push(text);
      this.onQueueUpdate([...this.pendingTranscripts]);
    }
  }

  private removeTriggerWord(text: string): string {
    const regex = new RegExp(`\\b${this.triggerWord}\\b`, 'gi');
    return text.replace(regex, '').trim();
  }

  sendAll(): void {
    if (this.pendingTranscripts.length === 0) return;

    const combinedText = this.pendingTranscripts.join(' ').trim();

    if (combinedText) {
      this.onSend(combinedText);
    }

    this.clear();
  }

  sendNow(): void {
    this.sendAll();
  }

  clear(): void {
    this.pendingTranscripts = [];
    this.onQueueUpdate([]);
  }

  getQueue(): string[] {
    return [...this.pendingTranscripts];
  }
}
```

### 3. Mode Switcher Component

```typescript
// electron/renderer/speech/speech-manager.ts
enum SendMode {
  AUTO = 'auto',
  TRIGGER_WORD = 'trigger-word'
}

export class SpeechManager {
  private recognitionManager: SpeechRecognitionManager;
  private autoSendMode: AutoSendMode;
  private triggerWordMode: TriggerWordMode;
  private currentMode: SendMode = SendMode.AUTO;

  constructor(
    private mcpClient: MCPClient,
    private ui: SpeechUI
  ) {
    this.recognitionManager = new SpeechRecognitionManager({
      lang: 'ru-RU',
      continuous: true,
      interimResults: true,
      maxAlternatives: 1
    });

    this.autoSendMode = new AutoSendMode(
      (text) => this.sendToMCP(text),
      (text) => this.ui.updateInterimText(text)
    );

    this.triggerWordMode = new TriggerWordMode(
      (text) => this.sendToMCP(text),
      (queue) => this.ui.updateQueue(queue)
    );

    this.setupRecognitionHandlers();
  }

  async startListening(): Promise<void> {
    await this.recognitionManager.start();
    this.ui.setState(OverlayState.LISTENING);
  }

  stopListening(): void {
    this.recognitionManager.stop();
    this.ui.setState(OverlayState.IDLE);
    this.currentMode === SendMode.AUTO
      ? this.autoSendMode.clear()
      : this.triggerWordMode.clear();
  }

  switchMode(mode: SendMode): void {
    // –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–µ–∂–∏–º
    this.currentMode === SendMode.AUTO
      ? this.autoSendMode.clear()
      : this.triggerWordMode.clear();

    this.currentMode = mode;
    this.ui.updateMode(mode);
  }

  setTriggerWord(word: string): void {
    this.triggerWordMode.setTriggerWord(word);
  }

  private setupRecognitionHandlers(): void {
    this.recognitionManager.onStart = () => {
      this.ui.setState(OverlayState.LISTENING);
    };

    this.recognitionManager.onInterimResult = (result) => {
      this.ui.setState(OverlayState.LISTENING);

      if (this.currentMode === SendMode.AUTO) {
        this.autoSendMode.handleInterimResult(result.transcript);
      } else {
        this.triggerWordMode.handleInterimResult(result.transcript);
      }
    };

    this.recognitionManager.onFinalResult = (result) => {
      this.ui.setState(OverlayState.RECORDING);

      if (this.currentMode === SendMode.AUTO) {
        this.autoSendMode.handleFinalResult(result.transcript, result.confidence);
      } else {
        this.triggerWordMode.handleFinalResult(result.transcript, result.confidence);
      }
    };

    this.recognitionManager.onError = (error) => {
      this.ui.setState(OverlayState.ERROR, {
        errorMessage: error.message
      });
    };

    this.recognitionManager.onEnd = () => {
      this.ui.setState(OverlayState.IDLE);
    };
  }

  private async sendToMCP(text: string): Promise<void> {
    this.ui.setState(OverlayState.PROCESSING);

    try {
      await this.mcpClient.sendUtterance(text);
      this.ui.setState(OverlayState.IDLE);
    } catch (error) {
      this.ui.setState(OverlayState.ERROR, {
        errorMessage: 'Failed to send to MCP server'
      });
    }
  }
}
```

### 4. UI Updates –¥–ª—è Speech

#### 4.1 –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ HTML

```html
<!-- electron/renderer/index.html -->
<div class="content">
  <!-- Existing status indicator -->
  <div class="status-indicator">
    <div class="status-dot"></div>
    <span>Ready</span>
  </div>

  <!-- Speech controls -->
  <div class="speech-controls">
    <button id="toggleListeningBtn" class="primary-btn">
      <svg><!-- Microphone icon --></svg>
      <span>Start Listening</span>
    </button>

    <!-- Mode switcher -->
    <div class="mode-switcher">
      <label>
        <input type="radio" name="sendMode" value="auto" checked>
        Auto-send
      </label>
      <label>
        <input type="radio" name="sendMode" value="trigger-word">
        Trigger Word
      </label>
    </div>

    <!-- Trigger word input (hidden by default) -->
    <div id="triggerWordSettings" class="trigger-word-settings hidden">
      <label>Trigger word:</label>
      <input type="text" id="triggerWordInput" value="send" placeholder="e.g. send, claude, go">
    </div>
  </div>

  <!-- Interim/pending text display -->
  <div class="speech-feedback">
    <div id="interimText" class="interim-text"></div>
    <div id="queuedMessages" class="queued-messages hidden"></div>
  </div>
</div>
```

#### 4.2 SpeechUI Helper Class

```typescript
// electron/renderer/speech/speech-ui.ts
export class SpeechUI {
  private stateIndicator: StateIndicator;
  private interimTextEl: HTMLElement;
  private queuedMessagesEl: HTMLElement;
  private toggleListeningBtn: HTMLButtonElement;
  private modeRadios: NodeListOf<HTMLInputElement>;
  private triggerWordSettings: HTMLElement;
  private triggerWordInput: HTMLInputElement;

  constructor(stateIndicator: StateIndicator) {
    this.stateIndicator = stateIndicator;
    this.interimTextEl = document.getElementById('interimText')!;
    this.queuedMessagesEl = document.getElementById('queuedMessages')!;
    this.toggleListeningBtn = document.getElementById('toggleListeningBtn') as HTMLButtonElement;
    this.modeRadios = document.querySelectorAll('input[name="sendMode"]');
    this.triggerWordSettings = document.getElementById('triggerWordSettings')!;
    this.triggerWordInput = document.getElementById('triggerWordInput') as HTMLInputElement;
  }

  setState(state: OverlayState, metadata?: any): void {
    this.stateIndicator.setState(state, metadata);

    // –û–±–Ω–æ–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É
    if (state === OverlayState.LISTENING || state === OverlayState.RECORDING) {
      this.toggleListeningBtn.textContent = 'Stop Listening';
      this.toggleListeningBtn.classList.add('active');
    } else {
      this.toggleListeningBtn.textContent = 'Start Listening';
      this.toggleListeningBtn.classList.remove('active');
    }
  }

  updateInterimText(text: string): void {
    this.interimTextEl.textContent = text;
    this.interimTextEl.classList.toggle('hidden', !text);
  }

  updateQueue(queue: string[]): void {
    if (queue.length === 0) {
      this.queuedMessagesEl.classList.add('hidden');
      this.queuedMessagesEl.innerHTML = '';
      return;
    }

    this.queuedMessagesEl.classList.remove('hidden');
    this.queuedMessagesEl.innerHTML = queue
      .map((msg, i) => `<div class="queued-message">${i + 1}. ${msg}</div>`)
      .join('');
  }

  updateMode(mode: SendMode): void {
    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º/—Å–∫—Ä—ã–≤–∞–µ–º trigger word settings
    if (mode === SendMode.TRIGGER_WORD) {
      this.triggerWordSettings.classList.remove('hidden');
    } else {
      this.triggerWordSettings.classList.add('hidden');
    }
  }

  getTriggerWord(): string {
    return this.triggerWordInput.value.trim() || 'send';
  }

  onModeChange(callback: (mode: SendMode) => void): void {
    this.modeRadios.forEach(radio => {
      radio.addEventListener('change', () => {
        if (radio.checked) {
          callback(radio.value as SendMode);
        }
      });
    });
  }

  onTriggerWordChange(callback: (word: string) => void): void {
    this.triggerWordInput.addEventListener('change', () => {
      callback(this.getTriggerWord());
    });
  }

  onToggleListening(callback: () => void): void {
    this.toggleListeningBtn.addEventListener('click', callback);
  }
}
```

### 5. MCP Integration

```typescript
// electron/main/mcp-client.ts
export class MCPClient {
  private port: number;
  private baseUrl: string;

  constructor(port: number = 5111) {
    this.port = port;
    this.baseUrl = `http://localhost:${this.port}`;
  }

  async sendUtterance(text: string): Promise<void> {
    const response = await fetch(`${this.baseUrl}/api/potential-utterances`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ text })
    });

    if (!response.ok) {
      throw new Error(`Failed to send utterance: ${response.statusText}`);
    }
  }

  async getVoiceState(): Promise<VoiceState> {
    const response = await fetch(`${this.baseUrl}/api/voice-state`);

    if (!response.ok) {
      throw new Error(`Failed to get voice state: ${response.statusText}`);
    }

    return response.json();
  }

  async setVoiceInputActive(active: boolean): Promise<void> {
    const response = await fetch(`${this.baseUrl}/api/voice-input-state`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ active })
    });

    if (!response.ok) {
      throw new Error(`Failed to set voice input state: ${response.statusText}`);
    }
  }
}
```

### 6. Permission Handling

```typescript
// electron/renderer/speech/permissions.ts
export class MicrophonePermissions {
  async request(): Promise<boolean> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º stream —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
      stream.getTracks().forEach(track => track.stop());

      return true;
    } catch (error) {
      console.error('Microphone permission denied:', error);
      return false;
    }
  }

  async check(): Promise<PermissionState> {
    try {
      const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      return result.state;
    } catch (error) {
      // Fallback –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–æ–≤ –±–µ–∑ Permissions API
      return 'prompt';
    }
  }

  showPermissionDialog(): void {
    // –ü–æ–∫–∞–∑–∞—Ç—å –¥–∏–∞–ª–æ–≥ —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—é —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π
    const dialog = document.createElement('div');
    dialog.className = 'permission-dialog';
    dialog.innerHTML = `
      <div class="dialog-content">
        <h3>Microphone Access Required</h3>
        <p>Voice Hooks needs access to your microphone to recognize speech.</p>
        <p>Click "Allow" when prompted by your browser.</p>
        <button id="requestPermissionBtn">Request Permission</button>
      </div>
    `;

    document.body.appendChild(dialog);

    document.getElementById('requestPermissionBtn')?.addEventListener('click', async () => {
      const granted = await this.request();

      if (granted) {
        dialog.remove();
      } else {
        alert('Microphone permission is required for voice recognition to work.');
      }
    });
  }
}
```

### 7. Auto-Restart Implementation

–£–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ `SpeechRecognitionManager.handleEnd()` –∏ `attemptRestart()`:

```typescript
private handleEnd(): void {
  this.isListening = false;

  // Auto-restart –µ—Å–ª–∏ listening –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω
  if (this.restartAttempts < this.maxRestartAttempts) {
    this.attemptRestart();
  } else {
    this.onEnd?.();
  }
}

private async attemptRestart(): Promise<void> {
  this.restartAttempts++;

  const delay = Math.min(1000 * this.restartAttempts, 5000);
  console.log(`Attempting restart (${this.restartAttempts}/${this.maxRestartAttempts}) in ${delay}ms`);

  await new Promise(resolve => setTimeout(resolve, delay));

  if (this.restartAttempts < this.maxRestartAttempts) {
    try {
      this.start();
    } catch (error) {
      console.error('Restart failed:', error);
      this.onEnd?.();
    }
  }
}
```

## –§–∞–π–ª–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```
electron/
‚îú‚îÄ‚îÄ renderer/
‚îÇ   ‚îú‚îÄ‚îÄ speech/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speech-recognition.ts      # (new) SpeechRecognition wrapper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speech-manager.ts          # (new) Main speech management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speech-ui.ts               # (new) UI helper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ permissions.ts             # (new) Microphone permissions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modes/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ auto-send.ts           # (new) Auto-send mode
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ trigger-word.ts        # (new) Trigger word mode
‚îÇ   ‚îú‚îÄ‚îÄ index.html                     # (modified) Add speech UI
‚îÇ   ‚îú‚îÄ‚îÄ styles.css                     # (modified) Add speech styles
‚îÇ   ‚îî‚îÄ‚îÄ main.ts                        # (modified) Initialize speech
‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îî‚îÄ‚îÄ mcp-client.ts                  # (new) MCP server client
‚îî‚îÄ‚îÄ preload/
    ‚îî‚îÄ‚îÄ types.ts                       # (modified) Add speech types
```

## –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏–µ–º–∫–∏

- [ ] Web Speech API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Electron
- [ ] Auto-send —Ä–µ–∂–∏–º: –æ—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ—Å–ª–µ –ø–∞—É–∑—ã (1.5 —Å–µ–∫—É–Ω–¥—ã)
- [ ] Trigger word —Ä–µ–∂–∏–º: –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ utterances –¥–æ trigger word
- [ ] –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏ –≤ UI
- [ ] Auto-restart –ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫ (–¥–æ 5 –ø–æ–ø—ã—Ç–æ–∫ —Å exponential backoff)
- [ ] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MCP server (–æ—Ç–ø—Ä–∞–≤–∫–∞ utterances)
- [ ] –í–∏–∑—É–∞–ª—å–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å (interim text, queued messages)
- [ ] –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å –ø–æ–Ω—è—Ç–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
- [ ] Unit —Ç–µ—Å—Ç—ã –¥–ª—è speech manager –∏ modes

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ (Story 1.6)

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Story 1.5:
1. Settings Panel - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (—è–∑—ã–∫, sensitivity –∏ —Ç.–¥.)
2. Keyboard Shortcuts - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
3. System Tray Integration

## –†–∏—Å–∫–∏ –∏ –º–∏—Ç–∏–≥–∞—Ü–∏—è

### –†–∏—Å–∫ 1: Web Speech API –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Electron
**–ü—Ä–æ–±–ª–µ–º–∞:** Electron –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å Web Speech API

**–ú–∏—Ç–∏–≥–∞—Ü–∏—è:**
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —ç—Ç–∞–ø–∞—Ö
- Fallback –Ω–∞ Node.js –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (e.g., `@google-cloud/speech`)
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

### –†–∏—Å–∫ 2: Auto-restart —Ü–∏–∫–ª
**–ü—Ä–æ–±–ª–µ–º–∞:** –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –æ—à–∏–±–∫–∞—Ö

**–ú–∏—Ç–∏–≥–∞—Ü–∏—è:**
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ (5)
- Exponential backoff (1s, 2s, 3s, 4s, 5s)
- –ü–æ–ª–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞

### –†–∏—Å–∫ 3: Trigger word –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
**–ü—Ä–æ–±–ª–µ–º–∞:** Trigger word –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–∏–∑–Ω–µ—Å—ë–Ω —Å–ª—É—á–∞–π–Ω–æ

**–ú–∏—Ç–∏–≥–∞—Ü–∏—è:**
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π trigger word
- Case-insensitive matching
- –û–ø—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è trigger word mode

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# Development
npm run electron:dev

# Unit tests
npm test -- --testPathPattern=speech

# Integration tests
npm test -- --testPathPattern=speech-integration
```
